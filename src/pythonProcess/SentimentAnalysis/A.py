# -*- coding: utf-8 -*-
"""TwitterPullData.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1Kq0fPHTKnvK4AYfaRYccMnxmn8TxjYa3
"""
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import requests
import os
import json
import pandas as pd
import argparse
import matplotlib.pyplot as plt
plt.figure(figsize=(5.2, 3.08))

bearer_token = "AAAAAAAAAAAAAAAAAAAAAJTaUgEAAAAAJMYYRQkRE78A6L60A5BsD0aQh2Q%3D1MIpS02Tmc3NUSS4vZqEbbnUDFjyp0z3Sd3taQNe47JFwrPKqx"

search_url = "https://api.twitter.com/2/tweets/search/recent"

# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,
# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields
def define_parameters(company_hanlde):
    return {'query': company_hanlde,'max_results':100}

def bearer_oauth(r):
    """
    Method required by bearer token authentication.
    """

    r.headers["Authorization"] = f"Bearer {bearer_token}"
    r.headers["User-Agent"] = "v2RecentSearchPython"
    return r

def connect_to_endpoint(url, params):
    response = requests.get(url, auth=bearer_oauth, params=params)
    #print("Status Code: " + str(response.status_code))
    #print("Data Retrieved for company")
    if response.status_code != 200:
        raise Exception(response.status_code, response.text)
    return response.json()

def request(company_handle):
    return connect_to_endpoint(search_url, define_parameters(company_handle))



def extractData(companyTwitter: str) -> None:
    rawData = request(companyTwitter)
    tweets = rawData['data']
    tweetsDataFrame = pd.DataFrame(tweets, columns=["id","text"])
    # tweetsDataFrame.to_csv('{}_latest_tweets.csv'.format(companyTwitter), index=True)
    f = open("{}.txt".format(companyTwitter), 'w')
    for t in tweets:
      f.write(t['text'].replace("\n", " ").rstrip('\t') + "\n")


    analyser = SentimentIntensityAnalyzer()

    all_scores = []
    for tweets in tweets:
        sentence = tweets['text']
        score = analyser.polarity_scores(sentence)
        all_scores.append(score)
    averagePositiveScore = 0
    averageNegaitveScore = 0
    averageNeutralScore = 0
    for currentScore in all_scores:
        positiveScore = currentScore['pos']
        negativeScore = currentScore['neg']
        neutralScore = currentScore['neu']

        averagePositiveScore+=positiveScore
        averageNegaitveScore+=negativeScore
        averageNeutralScore+=neutralScore

    #print(averagePositiveScore/100, averageNegaitveScore/100, averageNeutralScore/100)
    labels = ["Positive", "Negative", "Neutral"]
    sizes = averagePositiveScore/100, averageNegaitveScore/100, averageNeutralScore/100
    colors = ['#728E2B','#E15759', '#4E79A7']
    explode = (0.1, 0, 0)
    plt.rcParams['text.color'] = "white"
    #plt.rcParams['legend.background'] = "none"
    plt.pie(sizes, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)
    plt.legend(labels, loc="best")
    plt.axis('equal')
    plt.savefig("{}_pie.png".format(companyTwitter), transparent=True)
    #plt.show()
    #return {'Positive':averagePositiveScore/100, 'Negative':averageNegaitveScore/100, 'Neutral':averageNeutralScore/100}
    return
if __name__=='__main__':
    parser = argparse.ArgumentParser(description='Sentiment Analysis')
    parser.add_argument('--company_handle', default='', help='Enter the company twitter hanlde')
    args = parser.parse_args()
    extractData(args.company_handle)